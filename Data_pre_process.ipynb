{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1tHwV0NE81i",
        "outputId": "859e8c8f-3418-49eb-e8e3-ccfaf8b88110"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.10.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.8.30)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->openai==0.28) (4.12.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->openai==0.28) (0.2.0)\n"
          ]
        }
      ],
      "source": [
        "pip install openai==0.28"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "d9BFexzNDTYV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import openai\n",
        "import json\n",
        "import math # useless"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vYyvTsTIDdq6"
      },
      "outputs": [],
      "source": [
        "openai.api_key = \"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\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_resumes(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    \n",
        "    if 'Resume' not in df.columns or 'Title' not in df.columns:\n",
        "        raise ValueError(\"The uploaded file must have 'Title' and 'Resume' columns.\")\n",
        "\n",
        "    all_resumes_json = []\n",
        "\n",
        "    # Loop through each resume in the DataFrame\n",
        "    for index, row in df.iterrows():\n",
        "        resume_title = row['Title']\n",
        "        resume_text = row['Resume']\n",
        "        \n",
        "        prompt = f\"\"\"\n",
        "        The following text is a resume. Categorize its content into four parts as JSON without altering the original text:\n",
        "        - \"Education\": Text related to degrees, schools, or certifications.\n",
        "        - \"Experience\": Text related to job roles, companies, or work descriptions.\n",
        "        - \"Skills\": Text listing technical proficiencies or skills.\n",
        "        - \"Projects\": Text describing project details or achievements.\n",
        "\n",
        "        Provide only the JSON object in your response, without any additional explanation. Do not modify the text content; just categorize it. For example:\n",
        "\n",
        "        {{\n",
        "            \"Education\": \"Original text for education here\",\n",
        "            \"Experience\": \"Original text for experience here\",\n",
        "            \"Skills\": \"Original text for skills here\",\n",
        "            \"Projects\": \"Original text for projects here\"\n",
        "        }}\n",
        "\n",
        "        Resume: {resume_text}\n",
        "        \"\"\"\n",
        "        try:\n",
        "            response = openai.ChatCompletion.create(\n",
        "                model=\"gpt-4\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are an expert in resume parsing.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ],\n",
        "                temperature=0.7,\n",
        "                max_tokens=1000\n",
        "            )\n",
        "            \n",
        "            content = response['choices'][0]['message']['content'].strip()\n",
        "\n",
        "            try:\n",
        "                parsed_json = json.loads(content)\n",
        "                parsed_json['Title'] = resume_title  # Include the title in the JSON\n",
        "            except json.JSONDecodeError:\n",
        "                # If parsing fails, include the raw content as a string\n",
        "                parsed_json = {\"RawResponse\": content, \"Title\": resume_title}\n",
        "            \n",
        "            # Append the parsed or raw result to the list\n",
        "            all_resumes_json.append({\n",
        "                \"ResumeIndex\": index,\n",
        "                \"ResumeJSON\": parsed_json\n",
        "            })\n",
        "\n",
        "        except Exception as e:\n",
        "            # Log errors for this resume\n",
        "            all_resumes_json.append({\n",
        "                \"ResumeIndex\": index,\n",
        "                \"Error\": str(e),\n",
        "                \"Title\": resume_title\n",
        "            })\n",
        "    \n",
        "    # Save the consolidated JSON output\n",
        "    output_path = \"processed_resumes_with_titles_and_content.json\"\n",
        "    with open(output_path, \"w\") as f:\n",
        "        json.dump({\"Successful Candidate Profile\": all_resumes_json}, f, indent=4)\n",
        "    \n",
        "    print(f\"Processing complete. Results saved to {output_path}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_job_descriptions(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    \n",
        "    if 'JD' not in df.columns or 'Title' not in df.columns:\n",
        "        raise ValueError(\"The uploaded file must have 'Title' and 'JD' columns.\")\n",
        "\n",
        "    all_jd_json = []\n",
        "\n",
        "    # Loop through each job description in the DataFrame\n",
        "    for index, row in df.iterrows():\n",
        "        jd_title = row['Title']\n",
        "        jd_text = row['JD']\n",
        "        \n",
        "        prompt = f\"\"\"\n",
        "        The following text is a job description. Categorize its content into four parts as JSON without altering the original text:\n",
        "        - \"Role\": Text related to job roles or work descriptions.\n",
        "        - \"Qualification\": Text related to key qualifications required for the role.\n",
        "\n",
        "        Provide only the JSON object in your response, without any additional explanation. Do not modify the text content; just categorize it. For example:\n",
        "\n",
        "        {{\n",
        "            \"Role\": \"Original text for role here\",\n",
        "            \"Qualification\": \"Original text for qualifications here\"\n",
        "        }}\n",
        "\n",
        "        Job Description: {jd_text}\n",
        "        \"\"\"\n",
        "        try:\n",
        "            response = openai.ChatCompletion.create(\n",
        "                model=\"gpt-4\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are an expert in parsing job descriptions.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ],\n",
        "                temperature=0.7,\n",
        "                max_tokens=500\n",
        "            )\n",
        "            \n",
        "            content = response['choices'][0]['message']['content'].strip()\n",
        "\n",
        "            try:\n",
        "                parsed_json = json.loads(content)\n",
        "                parsed_json['Title'] = jd_title  # Include the title in the JSON\n",
        "            except json.JSONDecodeError:\n",
        "                # If parsing fails, include the raw content as a string\n",
        "                parsed_json = {\"RawResponse\": content, \"Title\": jd_title}\n",
        "            \n",
        "            # Append the parsed or raw result to the list\n",
        "            all_jd_json.append({\n",
        "                \"JDIndex\": index,\n",
        "                \"JDJSON\": parsed_json\n",
        "            })\n",
        "\n",
        "        except Exception as e:\n",
        "            # Log errors for this job description\n",
        "            all_jd_json.append({\n",
        "                \"JDIndex\": index,\n",
        "                \"Error\": str(e),\n",
        "                \"Title\": jd_title\n",
        "            })\n",
        "    \n",
        "    # Save the consolidated JSON output\n",
        "    output_path = \"processed_job_descriptions_with_titles.json\"\n",
        "    with open(output_path, \"w\") as f:\n",
        "        json.dump({\"JobDescriptions\": all_jd_json}, f, indent=4)\n",
        "    \n",
        "    print(f\"Processing complete. Results saved to {output_path}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VRJrT5gECOM",
        "outputId": "bf816419-33e0-4528-c5f5-501d040fbdd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing complete. Results saved to processed_resumes.json.\n"
          ]
        }
      ],
      "source": [
        "process_resumes(\"Successful_Candidate_Profile.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8xiPnk_TwsA",
        "outputId": "c51e0145-6d72-48bb-fb0a-f898eacc29a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing complete. Results saved to processed_job_descriptions.json.\n"
          ]
        }
      ],
      "source": [
        "process_job_descriptions(\"Job_Description.csv\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
