[
    {
        "job_title": "DS",
        "resume": {
            "Education": "UNIVERSITY OF WATERLOO Bachelor of Science - BS, Theoretical and Mathematical Physics (2019 - 2024) K.R. MANGALAM WORLD SCHOOL High School Diploma",
            "Experience": "UNIVERSITY OF WATERLOO Data Science Researcher, January 2024 - Present (11 months), Waterloo, Ontario, Canada Working at Prof. Marek Stastna's Fluid Lab in the Department of Applied Mathematics. ENVIRONMENT AND CLIMATE CHANGE CANADA Data Scientist, May 2023 - September 2023 (5 months), Ottawa, Ontario, Canada. Software Developer, January 2023 - April 2023 (4 months), Gatineau, Quebec, Canada. Software Developer, September 2022 - December 2022 (4 months), Gatineau, Quebec, Canada. UNIVERSITY OF WATERLOO Undergraduate Research Assistant, May 2022 - May 2023 (1 year 1 month), Waterloo, Ontario, Canada. Working at Prof. Kevin Lamb\u2019s Fluid Lab in the Department of Applied Mathematics. ONTARIO MINISTRY OF GOVERNMENT AND CONSUMER SERVICES Web Developer and Designer, January 2022 - May 2022 (5 months), Toronto, Ontario, Canada. UNIVERSITY OF WATERLOO Undergraduate Teaching Assistant (WEEF TA), September 2021 - December 2021 (4 months), Waterloo, Ontario, Canada. YUJA Software Developer, January 2021 - April 2021 (4 months). VIRTIBOT Co-Founder, October 2020 - December 2020 (3 months), India. COOLAGE APP Web Developer, June 2020 - August 2020 (3 months). WOMENFORINDIA Social Work Intern, June 2020 - July 2020 (2 months), Delhi, India.",
            "Skills": "NumPy, Natural Language Processing (NLP), Generative AI, SQL, R, Python, Tensorflow, Git, AWS",
            "Projects": "Developed OCR software using OpenCV in Python to extract data from foreign permits, implemented preprocessing pipelines to handle variations in text such as font, size, and orientation, optimized disk space by creating file compression software in Python saving 40% disk space, and improved OCR accuracy for 10k+ permits, resulting in time and cost savings. Developed a user-centric website in WordPress, integrating Bootstrap for widgets and components, analyzed page views and interactions using Google Analytics to improve the website's structure, automated data summarization with Excel, reducing manual work by 40%, and applied agile frameworks for website versioning and UI enhancements with Adobe tools. Tutored Linear Algebra, Physics, and Calculus, solving doubts for hundreds of students. Conducted over 30 help sessions, engaging students and teaching core concepts. Critiqued more than 35 resumes and supported students with the co-op process. Conducted over 1000 test cases for software performance improvements, resolved more than 30 bug reports, automated testing using Java, Selenium, and Git, and enhanced API testing efficiency with Postman and automated test creation in Typescript. Built the company website with WordPress, HTML5, and CSS3. Leveraged AI and ML for chatbot and video-bot development. Expanded the company's online presence through networking skills. Created website components using React, Bootstrap, and HTML/CSS. Managed a team of 5-8 interns and launched a project for the 'Make in India' campaign. Collaborated with a national team to provide COVID-19 support solutions and raised funds to assist healthcare and law enforcement personnel."
        },
        "job_description": {
            "Role": "Develop advanced analytics and predictive models from design through implementation in the areas of pricing and promotion, marketing, merchandising, and other areas of the business as needed Participate in the research of analytical methods to find or advance solutions to business problems Clearly and concisely explain complex analytical findings to non-analytical peers and business leaders Create analytic datasets in collaboration with data engineering teams that involves data querying, cleaning, transformation, and feature engineering. Define requirements and test cases for Data validation and monitoring Author programming code (e.g., SQL, Python, R, spark) to assemble and analyze data, following/establishing/enhancing organizational standards and coding practices including code management (i.e. Documentation, use ofGit Hub). Lead and participate in peer code reviews for QA/QC/standards compliance. Train/Mentor other team members, provide developmental support where necessary Follow defined project management processes. Actively participate in project plan development and agile ceremonies (development of backlog, sprint planning, daily standups, retros/reviews) and documentation.",
            "Qualification": "Education: Bachelor\u2019s degree required, preferably with a quantitative focus (Statistics, Business Analytics, Data Science, Math, Economics, etc.) Master\u2019s degree preferred Masters + 1year / Bachelors + 2 years of experience in a data science/advanced analytics role, or demonstrated ability to perform job functions via academic project/internship experience Knowledge And Skills: Demonstrated knowledge of SQL, R and Python; Experience querying large datasets using SparkSQL or PySpark; Experience with ML frameworks such as scikit-learn, Tensorflow, Keras, Pytorch, etc.; Exposure with software development practices, object-oriented principles and test automation; Exposure to version control systems such as Git \u2013 experience preferred Experience with cloud-based analytics environments (Azure, AWS or GCP); Experience applying operational research, statistical and machine learning techniques such as regression, time series forecasting, clustering, optimization, etc.; Exposure to agile methodologies using project planning and tracking management tools e.g., JIRA; experience preferred Strong problem-solving skills and ability to troubleshoot complex distributed systems; Strong interpersonal skills, including the ability to communicate the business benefits of analytics; Availability to travel up to 10% of the time"
        }
    },
    {
        "job_title": "DS",
        "resume": {
            "Education": "Master of Science in Applied Computing University of Toronto, 2019 - 2020 Bachelor of Engineering in Computer Science Panjab University, 2014 - 2018",
            "Experience": "Lead Data Scientist SOTI, Greater Toronto Area, Canada (Aug 2023 - Present) Integrated LLMs into mobile device management platforms using AWS Bedrock and retrieval-augmented generation techniques. Improved customer support efficiency by leveraging GPT for sentiment analysis, achieving 25% faster response times and $55,000 in monthly cost savings. Senior Data Scientist SOTI, Greater Toronto Area, Canada (Aug 2022 - Aug 2023) Implemented MLOps pipelines with MLflow for machine learning deployments. Developed forecasting solutions increasing profit by $1 million through resource optimization. Data Scientist SOTI, Greater Toronto Area, Canada (Jan 2021 - July 2022) Designed machine learning solutions for device license renewal prediction and add-ons. Built ETL pipelines for efficient feature engineering and prediction scheduling. Machine Learning Research Intern Department of Computer Science, University of Toronto (Apr 2020 - Dec 2020) Conducted time series forecasting for device battery life prediction. Business Technology Analyst ZS Associates, Gurgaon, India (Jun 2018 - Jun 2019) Delivered data models and automated operations management using Python.",
            "Skills": "Programming: Python, Java Machine Learning: Time Series Forecasting, Unsupervised Learning, Generative AI Cloud Platforms: AWS (SageMaker, S3, EC2), Kubernetes, Docker MLOps: MLflow, Retrieval-Augmented Generation (RAG) techniques Tools & Technologies: TensorFlow, PyTorch, Pandas, NumPy, Redis, Semantic Search",
            "Projects": "LLM-Enhanced Mobile Device Management Developed a comprehensive architecture combining proprietary and open-source LLMs for JavaScript code generation, semantic search, and technical retrieval. Time Series Forecasting for Cost Optimization Built machine learning models to predict resource allocation needs, reducing unnecessary expenditures. Generative AI for Customer Support Fine-tuned GPT models for case summarization and sentiment analysis, leading to enhanced customer service experiences. HR Talent Tool with NLP Automated resume shortlisting and LinkedIn outreach to streamline recruitment processes."
        },
        "job_description": {
            "Role": "As an Applied Scientist Intern, you will: \u00a0 Experiment and Develop: You can be involved in the entire model development lifecycle, building, testing, and delivering high-quality solutions. Collaborate: Working on a collaborative cross-functional team, you will learn from and partner with colleagues across the globe.\u00a0 Innovate: You will have the opportunity to try new approaches and learn new technologies. You will contribute ideas and work on solving real-world challenges.",
            "Qualification": "You are fit for the Applied Scientist Intern role if your background includes some of the following: \u00a0 Be currently enrolled in a PhD program relevant discipline or Master\u2019s program with research experience. Have an understanding and experience with Natural Language Processing, and/or Machine Learning methods including Large Language Models. Have experience creating and evaluating experiments related to Machine Learning or Large Language Models. Have proficiency in implementing solutions using Python, DL/ML/NLP frameworks, and relevant tools. Have experience in using code collaboration and versioning systems such as GitHub. Have familiarity with cloud tools such as Amazon AWS, MS Azure, or Google Cloud. Are comfortable working with unstructured datasets and are knowledgeable about tools and techniques for data cleaning and processing. Have a data-driven problem-solving and decision-making mindset. Have good communication skills and the ability to work collaboratively as part of a team."
        }
    },
    {
        "job_title": "DS",
        "resume": {
            "Education": "University of Toronto - Rotman School of Management: Master's Degree in Management Analytics (2018 - 2019). University of Toronto: Bachelor's Degree in Financial Accounting (Specialization) (2014 - 2018), Minor in Computer Science (2015 - 2018).",
            "Experience": "Data Scientist at Visa (June 2022 - Present): Member of the Visa Consulting & Analytics group.  TD (3 years): Senior Data Analyst (April 2021 - June 2022) conducting pan-product advanced analytics for personal banking credit valuations, recognized with \u201cAbove and Beyond\u201d and \u201cTD Great Work\u201d awards. Data Scientist (July 2020 - April 2021) delivering enterprise advisory solutions for multiple business lines using customer, product, and transactional data, developing data pipelines and analysis using SQL, Hive, Python, PySpark, SAS, Tableau, and Excel. Analytics and Data Science Associate - Graduate Leadership Program (July 2019 - July 2020).  The Janssen Pharmaceutical Companies of Johnson & Johnson: Practicum Project - Customer Excellence Team (September 2018 - April 2019).  MassMutual Financial Group: Commercial Practice Program Intern (July 2014 - August 2014).",
            "Skills": "Technical skills include Python, SAS, SQL, Hive, PySpark, Tableau, and Excel. Soft skills include data analysis, visualization, and advanced analytics. Language proficiencies are English (Professional Working) and Chinese (Native or Bilingual). Certifications include SAS Certified Statistical Business Analyst Using SAS 9 and Base Programming for SAS9.",
            "Projects": "No specific projects were explicitly listed in the resume, but project-related tasks and recognitions (e.g., hackathons) are highlighted."
        },
        "job_description": {
            "Role": "Be an out-of-the-box thinker who is passionate about brainstorming innovative ways to use unique data to answer business problems. Communicate with clients to understand the challenges they face and convince them with data. Extract and understand data to form an opinion on how to best help clients and derive relevant insights. Develop visualizations to make complex analyses accessible to a broad audience. Find opportunities to craft products out of analyses that are suitable for multiple clients. Work with stakeholders throughout the organization to identify opportunities for leveraging Visa data to drive business solutions. Mine and analyze data from company databases to drive optimization and improvement of product, marketing techniques, and business strategies for Visa and its clients. Assess the effectiveness and accuracy of new data sources and data gathering techniques. Develop custom data models and algorithms to apply to data sets. Use predictive modeling to increase and optimize customer experiences, revenue generation, data insights, advertising targeting, and other business outcomes. Develop processes and tools to monitor and analyze model performance and data accuracy.",
            "Qualification": "Basic Qualifications Two years of relevant work experience with a Master's degree in an analytical field such as statistics, operations research, economics, computer science, or a related field, graduating January 2024 - August 2025. Preferred Qualifications Experience with extracting and aggregating data from large data sets using SQL or other tools. Competence in Excel, PowerPoint, and Tableau. Experience in understanding and analyzing data using statistical software (e.g., Python, SAS, R, Stata, or others). Previous exposure to financial services, credit cards, or merchant analytics is a plus, but not required."
        }
    },
    {
        "job_title": "DS",
        "resume": {
            "Education": "The George Washington University: Master of Science in Data Science (2020 - 2021). Flatiron School: Data Science Immersive Bootcamp in Data Science (2019). Imperial College London: Master of Science in Civil Engineering (2011 - 2012). The University of Sheffield: Master of Engineering in Civil Engineering (2004 - 2008).",
            "Experience": "Data Scientist at Everstream Analytics (July 2023 - Present): Works in Washington, DC, contributing to data-driven solutions and analytics. Data Scientist at Enquire (January 2021 - July 2023): Built infrastructure to deploy NLP applications, managed machine learning model life cycles, deployed ML features, and architected data pipelines in AWS to support various applications. Civil Engineer at Atkins (February 2013 - December 2017): Worked in London, focusing on engineering projects. Civil Engineer at Wonwoo Structural Engineers (October 2009 - October 2010): Based in Seoul, Korea, handled structural engineering tasks. Civil Engineer at Consolidated Consultants (October 2008 - October 2009): Worked in Amman, Jordan, focusing on consulting and engineering services.",
            "Skills": "Proficient in data science, Python, SQL, natural language processing, and AWS infrastructure. Certifications include XCS224U - Natural Language Understanding, XCS236 - Deep Generative Models, XCS224N - Natural Language Processing with Deep Learning, and the Artificial Intelligence Professional Program.",
            "Projects": "Detecting leukemic B-lymphoblast cells: This project assesses the accuracy of a built-from-scratch CNN model and a ResNet50 pre-trained transfer learning CNN model in distinguishing leukemic B-lymphoblast cells (cancer cells) from healthy B-lymphoid precursors (normal cells). Microscopic blood smear images from healthy and Leukemia-diagnosed patients were used for analysis. Fake News Classifier: Explored different classification models using datasets from Kaggle for fake news detection. Tested models include: Neural Network with Bi-directional recurrent LSTM cell layer using Stanford's Glove-300d embeddings. Neural Network with conventional, max-pooling, and recurrent/LSTM-cell layers using Stanford's Glove-300d embeddings. Pre-trained NNLM 128 Model embedding layer with a dense classifier layer. Naive Bayes. Models were evaluated for performance across multiple datasets."
        },
        "job_description": {
            "Role": "As a Data Scientist at Everstream Analytics, your focus will be to implement models, algorithms, experiments and deployable code that bridge operational needs with strategic vision. The focus of the position is working on logistics insights on shipment data to produce insights on the paths of and risks to cargo movement worldwide. You will learn current processes, build data backed solutions, automate solutions, launch your work to production, and audit implementation. In the simplest terms, we want candidates who have experience building models to solve real industry problems that have been deployed in a real production software environment and where the model performance was really important.",
            "Qualification": "\u2022 Bachelor of Science in Computer Science, Statistics, Mathematics, Physics, or related field.\n\u2022 3+ years experience in building and delivering predictive analytics models using advanced machine learning algorithms and techniques such as: classification, outlier detection, clustering, and boosting.\n\u2022 Good scripting and programming skills with experience using Python and other packages for data analysis.\n\u2022 Practical knowledge in applying modeling concepts such as graph algorithms, optimization, time series, classification, etc.\n\u2022 Experience with analytical development tools including libraries such as Pandas, NumPy, Scikit-learn, PyTorch, and LightGBM.\n\u2022 Database knowledge/ experience: PostgreSQL or other open source/ Relational Databases.\n\u2022 Bonus Skills\n\u2022 Advanced Degree (PhD, MS, or GradCert).\n\u2022 Supply-Chain and Transportation Industry Experience.\n\u2022 Domain experience: Supply Chain, Logistics, Risk Mgmt, ESG, Sustainability, Weather & Climate.\n\u2022 Proficiency in using query languages such as SQL with experience in a Big Data environment.\n\u2022 Experience developing applications in AWS.\n\u2022 Experience in a Software Development Environment.\n\u2022 Full Stack Data Science: full deployment process of a model.\n\u2022 Real models deployed to solve real problems."
        }
    },
    {
        "job_title": "DS",
        "resume": {
            "Education": "Ryerson University: Bachelor\u2019s Degree in Computer Science (2014 - 2017).",
            "Experience": "Big Data Engineer at TD (July 2017 - Present): Based in Toronto, Canada, contributing to big data engineering solutions. Software Developer at Dapasoft (July 2015 - August 2016): Collaborated on auto-documenting tools for Ontario Electronic Stewardship, researched integration solutions with MS SQL Server and MS Access, generated test scenarios, and worked extensively with .Net Framework. Census Enumerator at Statistics Canada (May 2016 - July 2016): Conducted in-person interviews to collect Census data for the Government of Canada. Software Analyst, .Net Programmer at Cineplex Entertainment (January 2013 - April 2013): Assisted departments with software needs, developed and tested software using C#, ASP.NET, and jQuery, and ensured department requirements were met. QA Analyst at Microinformatix (May 2011 - August 2011): Tested and deployed applications within the .Net framework, researched software development processes, applied test cases, and worked with Visual Studio, Silverlight, and Azure platforms. Electrical/Software Assistant at Mars Rover Team, University of Waterloo (January 2011 - April 2011)",
            "Skills": "Technical skills include C#, MATLAB, Java, Python, and extensive experience with .Net Framework, MS SQL Server, Azure, and SharePoint. Language proficiencies are English (Native or Bilingual) and French (Limited Working).",
            "Projects": "Contributed to projects using Python, C, Qt Designer, Linux, and PCB circuit boards."
        },
        "job_description": {
            "Role": "The Data Scientist II, Analytics and Insights, Financial Crimes will use an analytics-focused approach to uplift the Bank's Financial Crime mitigation, detection, and investigation programs. You'll be part of a group of diverse, inclusive, and collaborative Data Scientists & Analytics Specialists, taking an integrated approach as you build relationships with business owners and internal partners in TD. With your deep knowledge of the business world, its organizational makeup, and practices, you'll develop key insights to address their rapidly growing data and information needs, business objectives and opportunities for improvement. Your pod will be integral in the delivery of ongoing analytics projects as well as comprehensive ongoing support. Most importantly, you will drive to execute with speed and precision and help bring TD into the future of business. As the Data Scientist II, Analytics and Insights, Financial Crimes you will: \u2022 Create Financial Crime mitigation strategies based on advanced analytics approaches \u2022 Develop analytic solutions to support insight generation that align to strategy and drive shareholder value \u2022 Lead large complex analytics projects to identify opportunities to further optimize our current product suite through self-initiated insights \u2022 Present insights back to leaders and business partners to drive strategic improvement \u2022 Review and/or build the presentation of insights back to executive leaders/business partners to drive strategic improvement \u2022 Collaborate with business partners to shape and prioritize ad hoc analysis \u2022 Use data systems and various sources to ensure team is equipped to formulate well-defined solutions to solve business problems \u2022 Create the development and ongoing analysis for a business line or functional area employing both internal and external data from various sources",
            "Qualification": "\u2022 Strong ownership mentality, proactive attitude, and ability to get things done \u2022 Demonstrated passionate analytical thinker with track record of delivering business impact and results through developing and executing on innovative analytics solutions \u2022 Strong problem-solving skills, with a history of using data to understand not only what is happening, but why it is happening, and what can be done to resolve the issue \u2022 Ability to use predictive analytics, customer segmentation, and sensitivity analysis to develop detailed business cases and explain business value of projects \u2022 Ability to translate complex problems and solutions into a simple story, tailored to executive audiences \u2022 Excellent interpersonal and communication skills, both written and verbal \u2022 Demonstrated ability to learn and apply new analytical techniques and adapting to the evolution within the financial services industry \u2022 Understanding of products and strategies to challenge business cases and analyses \u2022 Capable of working in and across teams, leading partners and aligning leadership \u2013 including proven teamwork and ability to build deep relationships with diverse business partners \u2022 Strong organizational skills, with the ability to excel in a fast-paced environment and run multiple deadlines and priorities \u2022 Strong understanding of test and experimental design (Test and Learn) \u2022 Aspirations to build in-depth industry knowledge, including current big data trends and challenges globally"
        }
    },
    {
        "job_title": "DS",
        "resume": {
            "Education": "University of Tehran: Master's degree in Computer Engineering. Shiraz University of Technology: Bachelor's degree in Computer Engineering Information Science.",
            "Experience": "Data Scientist at Teranet Inc. (March 2024 - Present): Working in Toronto, focusing on data science applications. Data Analyst at The Globe and Mail (April 2022 - December 2023): Developed machine learning models for marketing and subscription analytics, improving conversion rates and customer retention. Delivered insights through statistical analysis, predictive modeling, and A/B testing. Application Data Scientist at MUUTAA (January 2021 - April 2022): Built time series forecasting models for inventory management, reducing forecasting error and improving inventory planning. Provided actionable insights on COVID-19's financial impact and implemented predictive models to optimize business strategies. Application Data Scientist at Telecommunication Company of Iran - TCI (October 2019 - January 2021): Designed machine learning models for customer targeting and market growth prediction, achieving increased customer acquisition and operational efficiency.",
            "Skills": "Proficient in Python, SQL, and Spark SQL. Experienced with machine learning techniques (regression, neural networks, ensemble methods), deep learning models (CNNs, RNNs, LSTMs), and cloud platforms (Azure, AWS, Snowflake). Proficient in statistical analysis, data visualization (Tableau, PowerBI), and tools like TensorFlow, Keras, and Databricks.",
            "Projects": "Lead Scoring through Machine Learning: Optimizing Marketing Campaigns (May 2023 - June 2023): Conducted at The Globe and Mail to enhance marketing campaign productivity by focusing on high-potential leads. Advanced machine learning algorithms were employed to classify leads, improving resource management and campaign effectiveness. GitHub - Lead Conversion Score Prediction. A Benchmark Study of Machine Learning Models for Online Fake News Detection (October 2022 - December 2022): Aimed to detect fake news using machine learning and deep learning techniques by analyzing text data exclusively, without relying on graphs, social networks, or images. GitHub - Fake News Detector."
        },
        "job_description": {
            "Role": "The Data & Analytics team within the Commercial Solutions line of business has an ambitious mandate, where we are accountable for leveraging Data & Analytics to deliver business value both internally as well as to external clients through the following: Enhance existing or create new products and services with proprietary data assets and partnering with external data providers, through the application of data analytics. Design and deliver custom data solutions to fulfill specific client needs. Explore and analyze data to generate business insights to enhance decision-making. Demonstrate thought leadership in the ecosystem in which we operate. Identify and implement opportunities for operational efficiencies across the organization. This team will play an important role in evangelizing and educating of the value of Data & Analytics to the rest of the organization, in support of cultivating a data-driven culture. The Data Scientist will play a key role in our dynamic team, taking accountability for the design, development, implementation, and maintenance of cutting-edge Machine Learning models. As a vital member of the Data Science team, the role involves collaborating closely on Machine Learning (ML) and Artificial Intelligence (AI) product design and development. The primary focus will be on supporting data products/services and operational efficiency initiatives. This includes a special emphasis on providing tailored products for Financial Solutions business and expanding these capabilities across the organization to address a diverse range of AI needs. Join us in shaping the future of our data-driven initiatives and contributing to innovative solutions that make a meaningful impact. You will be accountable for the entire lifecycle of each assigned ML/AI use case, from gathering business requirements all the way to production and maintenance. You are a self-starter with the ability to think critically. You have experience working in an agile environment and flexible to accommodate evolving deliverables in a challenging and ambitious space.",
            "Qualification": "A Graduate Degree in STEM (Science, Technology, Engineering, or Mathematics) fields is preferred, with an emphasis on Data Science, Statistics, Computer Science or related disciplines. Equivalent professional experience will be considered. 5+ years of proficiency in Python programming language, with a strong emphasis on machine learning applications. Have a solid track record of 5+ years in creating ML models, especially advanced regression models, utilizing boosting methods and model stacking. Solid understanding of statistical concepts and their application in data science. Experience with cloud architecture (e.g., AWS, Azure, Google Cloud) and PySpark. A significant plus to have proficiency in any/ all the followings: -Spatial Data Science and real estate valuation models -Advanced statistical analysis and economics -Artificial Neural Networks (ANN) for regression analysis. Experience with data query languages such as SQL. Skills in data visualization tools, such as Tableau, for effective presentation of analytical findings. Strong knowledge of deep learning techniques and their practical applications."
        }
    },
    {
        "job_title": "DS",
        "resume": {
            "Education": "University of Toronto: Master of Engineering in Industrial Engineering (2019 - 2020). McMaster University: Bachelor of Engineering in Mechanical Engineering Co-op (2014 - 2019).",
            "Experience": "Senior Data Engineer at Manulife (March 2023 - Present): Works on the Generative AI Platform Team, building robust data pipelines and infrastructure. Data Engineer at Kora (January 2023 - March 2023): Automated finance reconciliation and reporting, developed Flask APIs for monitoring, and built PySpark big data pipelines on AWS EMR for operational datasets and regulatory reporting. Junior Data Engineer at Kora (January 2022 - January 2023): Maintained AWS big data infrastructure and implemented AWS Athena for ad-hoc analytics. Process Automation/Data Analyst at Sanofi Pasteur (February 2021 - January 2022): Developed full-stack web applications to optimize quality validation processes, built ETL pipelines for dashboards, and identified areas for improvement in quality control labs. Data Scientist Co-op at FGF Brands (May 2020 - August 2020): Designed Power BI dashboards for actionable insights, supported data science projects with preprocessing, and enhanced dashboard functionality with Python and Power Apps. Continuous Improvement Co-op at FGF Brands (May 2019 - August 2019): Automated KPI reports, analyzed production efficiency data, and implemented time-saving opportunities in production processes. Student Engineer, Process at Apotex Inc. (May 2017 - April 2018): Managed process improvement initiatives, automated production reports, and collaborated on custom equipment design for manufacturing enhancements. Operations Intern at Weston Foods (May 2016 - August 2016): Produced QA KPI reports, coordinated cleaning validation programs, and managed external vendor schedules for QC asset calibration.",
            "Skills": "Proficient in Python, PySpark, SQL, and Azure Data Factory. Experienced in big data engineering, cloud platforms (Azure, AWS), and data visualization tools (Power BI, Plotly). Language proficiencies include English (Native or Bilingual) and Cantonese (Native or Bilingual).",
            "Projects": ""
        },
        "job_description": {
            "Role": "\u2022 Develop and implement machine learning models to solve complex business problems, using a variety of algorithms and techniques. \u2022 Clean, preprocess, and analyze large datasets to extract meaningful insights and patterns. \u2022 Apply prompt engineering techniques, build with RAG (Retrieval-Augmented Generation) applications, and fine-tune language models and improve their performance in specific tasks. \u2022 Collaborate with multi-functional teams to identify and define business requirements, ensuring alignment with data science objectives. \u2022 Apply generative AI techniques to generate synthetic data, create realistic simulations, and enhance data analysis capabilities. \u2022 Design and complete experiments to validate and optimize machine learning models, ensuring accuracy, efficiency, and scalability. \u2022 Deploy machine learning models and applications on cloud platforms like Azure ML or Databricks, ensuring seamless integration and scalability. \u2022 Stay up-to-date with the latest advancements in machine learning, generative AI, prompt engineering, RAG applications, and cloud technologies, and apply them to enhance our data science capabilities. \u2022 Collaborate with data engineers and ML engineers to integrate data science solutions into existing systems and workflows. \u2022 Communicate complex technical concepts and findings to both technical and non-technical partners, ensuring clear understanding and agreement.",
            "Qualification": "\u2022 Bachelor', Master's degree, or Ph.D. in Computer Science, Data Science, Statistics, or a related field. \u2022 Proven experience as a Data Scientist including internships or coops, with a strong focus on machine learning, generative AI, prompt engineering, and RAG applications. \u2022 Solid understanding of machine learning algorithms, statistical modeling, and data analysis techniques. \u2022 Proficiency in programming languages such as Python and experience with machine learning libraries/frameworks (e.g., PyTorch, scikit-learn, Hugging Face). \u2022 Strong problem-solving skills and the ability to think critically and creatively to develop innovative solutions. \u2022 Excellent communication and collaboration skills, with the ability to work effectively in multi-functional teams."
        }
    },
    {
        "job_title": "DS",
        "resume": {
            "Education": "University of Toronto: Master of Science in Statistics (September 2021 - August 2023). University of Toronto: Bachelor\u2019s Degree in Mathematics and Statistics (2016 - 2021).",
            "Experience": "Analyst at Rakuten Rewards (August 2024 - Present): Analyzing data to support business and marketing decisions. Data Scientist at Moloco (September 2022 - December 2022): Engaged in data science tasks, contributing to the company\u2019s analytics capabilities. Machine Learning Engineer at RBC (May 2022 - August 2022): Developed an NLP model using the TF-IDF technique to extract keywords, increasing user engagement and email open rates by up to 50%. Utilized parallel programming to optimize table generation and reduce complexity. Database Developer at IBM (May 2020 - August 2020): Monitored SQL servers and database performance for IBM Cognos Analytics. Built custom query engines and debugged over 50 relational databases. Performance Data Analyst at AMD (May 2019 - May 2020): Developed a Generalized Linear Model for battery life and automated performance benchmark scripts, improving efficiency by 50%. Created marketing documents with Tableau for executive support.",
            "Skills": "Proficient in SQL, Python, Bash, Powershell, and data visualization tools like Tableau. Experienced in multivariate statistics, NLP, and A/B testing. Language proficiencies include Korean (Native or Bilingual) and English (Native or Bilingual).",
            "Projects": ""
        },
        "job_description": {
            "Role": "\u2022 Collaborate with manager and stakeholders to specify business problems with precision \u2022 Support the translation of business problems into machine learning problems, including ML problem formulation and evaluation metric specification. \u2022 Perform exploratory data analyses to characterize utility of existing data and to identify needs for new data \u2022 Develop data pipelines for feature computation, model training, inference and evaluation \u2022 Design and execute offline experiments and simulations \u2022 Lead model deployment, business integration and online performance assessment \u2022 Maintain technical documentation, develop/present demos and presentations \u2022 Support management in project planning and status reporting",
            "Qualification": "\u2022 Very strong SQL skills \u2022 Experience with big data and machine learning frameworks. Python/sklearn/pytorch strongly preferred. \u2022 Practical experience with multiple ML problem types (supervised/unsupervised, classification/regression, RL experience is a plus) \u2022 Strong software development skills \u2022 Strong problem solving, communication and collaboration skills \u2022 Firm understanding of statistics and A/B test fundamentals \u2022 Experience with NLP techniques is a plus \u2022 Deep learning/NN experience is a plus \u2022 5+ years industry experience applying machine learning methods to solve real-world problems \u2022 Bachelor\u2019s degree in AI/ML, computational mathematics, computer science, statistics, physics or related field. Master\u2019s degree strongly preferred. \u2022 Experience in ad-tech and/or consumer services is a plus"
        }
    },
    {
        "job_title": "DS",
        "resume": {
            "Education": "McGill University: Bachelor of Science in Joint Honours Mathematics & Physics (2009 - 2012). Marianopolis College: DEC in Pure & Applied Science (2007 - 2009).",
            "Experience": "Senior Software Engineer at Grafana Labs (March 2022 - Present): Works in cloud engineering and R&D. Software Development Manager at MindGeek (May 2021 - February 2022): Led cloud data engineering services. Lead Software Developer at MindGeek (September 2020 - May 2021): Managed cloud data engineering services. Senior Software Developer at MindGeek (July 2019 - September 2020): Contributed to cloud data engineering projects. Contract Software Developer (Self-employed) (July 2018 - February 2022): Delivered software development solutions in Montreal. Bioinformatics Software Developer at Centre for High-Throughput Biology (Pavlidis Lab) (August 2014 - July 2018): Focused on large-scale computational methods and neuroinformatics research, incorporating DevOps best practices for web application management. Software Developer at Pivotal Payments (2010): Contributed to software development projects. Financial Analyst/Developer at Pivotal Payments (2008 - 2010): Provided analytical and development services.",
            "Skills": "Expertise in software development, DevOps, database design, and data science. Proficient in end-to-end application architecture, cloud engineering, and bioinformatics tools. Language proficiencies include English (Native or Bilingual) and French (Limited Working).",
            "Projects": ""
        },
        "job_description": {
            "Role": "\u2022 Refine our existing time series forecasts to allow the prediction of per-customer consumption, with an emphasis on ensuring model explainability and a clear representation of model uncertainty \u2022 Partner with Data Engineering to ensure the model infrastructure is in place to serve, monitor, test, and retrain any models put into production \u2022 Identify and build solutions to leverage these forecast models for operational use cases (e.g., customer consumption anomaly detection, alerting, etc.) \u2022 Partner closely with RevOps to both understand and predict customer consumption as a part of our sales planning and territory management \u2022 Collaborate across Product, R&D, and Data Engineering to identify and ingest new sources of data to improve model performance",
            "Qualification": "\u2022 Extensive experience building production-ready ML models for time series applications \u2022 5 - 7+ years of experience with Python and familiarity with SQL \u2022 Hands-on experience with cloud data warehouses (e.g., BigQuery, Snowflake, Redshift, etc.) \u2022 Highly motivated self-starter that is keen to make an impact and is unafraid of tackling large, complicated problems \u2022 Excellent communication skills, able to explain technical topics to non-technical audiences, and maintain many of the essential cross-team and cross-functional relationships necessary for the team\u2019s success \u2022 Experience in Bayesian statistics and modeling \u2022 Knowledge about observability \u2022 Previous experience with Grafana visualization, or a desire to invest the time to learn"
        }
    },
    {
        "job_title": "DS",
        "resume": {
            "Education": "The University of Chicago: Bachelor of Arts in Economics and Law, Letters, and Society (2012 - 2016). The Lawrenceville School: Diploma (2009 - 2012).",
            "Experience": "Data Science Manager at Coalition, Inc. (November 2023 - Present): Managing data science initiatives in the New York City Metropolitan Area. Senior Data Scientist at Coalition, Inc. (September 2023 - November 2023): Worked on advanced data science solutions. Data Scientist II at Coalition, Inc. (July 2021 - August 2023): Contributed to data science projects and analytics. Data Scientist I at Coalition, Inc. (April 2020 - June 2021): Developed and implemented data-driven solutions. Senior Business Analyst, Strategy & Analytics at Affirm, Inc. (April 2019 - April 2020): Focused on strategy and analytics in the San Francisco Bay Area. Business Analyst, Strategy & Analytics at Affirm, Inc. (June 2018 - March 2019): Delivered insights for strategic planning. Associate at Charles River Associates (September 2017 - May 2018): Worked on antitrust and competition economics in the Washington D.C. Metro Area. Analyst at Charles River Associates (August 2016 - August 2017): Contributed to economic analysis for antitrust cases. Business Analyst Intern at Sears Holdings Corporation (June 2015 - August 2015): Worked in eCommerce core product management.",
            "Skills": "Proficient in Microsoft Excel, Microsoft PowerPoint, and economics. Language skills include English (Native or Bilingual), Korean (Native or Bilingual), Chinese (Elementary), and Latin.",
            "Projects": ""
        },
        "job_description": {
            "Role": "\u2022 Lead cross-functional projects using quantitative analysis and advanced data modeling to discover insights that will guide strategic decisions and uncover optimization opportunities for our security and underwriting business.   \u2022 Influence leadership & make us more efficient with data-backed recommendations, tracking OKRs etc   \u2022 Collaborate with Product, Analytics, Engineering, and Business team members to help report on KPIs, OKR performance monitoring, and metrics anomalies   \u2022 Combine/Integrate new data sources and be able to put together new narratives based on the data   \u2022 Ability to analyze disparate data sources and synthesize into a narrative of what is happening in the data   \u2022 E-staff level and board deck preparation and support   \u2022 Contribute and grow the culture of data excellence on our team by bringing mature empathy, best practices, and processes to our organization",
            "Qualification": "\u2022 A Bachelor's degree in Statistics, Economics, Mathematics or related technical field   \u2022 1-2 years of experience in related analytical, data science or consulting background   \u2022 Expert SQL proficiency with proven competencies in designing well-architected data models, optimizing for query performance, and clearly documenting code   \u2022 Experience working with data in Python, R and similar tools   \u2022 Work in Tableau, Looker, or similar visualization / business intelligence platform   \u2022 Strong communication skills and ability to convey complex topics to non-technical audiences   \u2022 Understanding of and experience with experimental design and statistical methods    \u2022 Passion, drive, and a deep sense of responsibility. We build the systems that keep us and our customers safe!"
        }
    },
    {
        "job_title": "DS",
        "resume": {
            "Education": "University of Toronto: Master of Arts in Economics (August 2021 - April 2022). University of Waterloo: Bachelor\u2019s Degree in Honours Pure Mathematics with a Computer Science Minor (2016 - 2021). Royal Conservatory of Music: Associate of the Royal Conservatory of Toronto (ARCT) in Piano Performance (2015 - 2016).",
            "Experience": "Analytics Engineer at Definity (July 2024 - Present): Builds zero-to-one data products to support core pricing initiatives. Data Scientist at Honey Health (April 2024 - June 2024): Served as the first data scientist at a health tech startup, driving analytics initiatives. Data Scientist at Wish (November 2022 - October 2023): Improved product quality and user experience through experimentation, machine learning, and dashboard development. Contributions included enhancements to recommendation systems, seller incentive structures, and search query processing. Teaching Assistant at University of Toronto (September 2021 - April 2022): Assisted in courses on data tools for economists and introductory microeconomics, mentoring students and hosting tutorials. Undergraduate Research Assistant at University of Waterloo (May 2020 - August 2020): Conducted combinatorics and quantum field theory research, culminating in a preprint publication.",
            "Skills": "Proficient in Python, R, SQL, and C++. Experienced in data visualization (Superset, Tableau), pipeline development (Airflow), and advanced modeling techniques, including Bayesian methods and machine learning. Language proficiencies include English (Native or Bilingual) and French (Limited Working).",
            "Projects": "Implemented a novel application of large language models (LLMs) and vector search to classify products into themes, transforming the user browsing experience at Wish from product-based to theme-based discovery. Guided a cross-functional team of over 30 members across product management, engineering, design, and operations to mature the prototype into a production-ready system. Developed a model to predict industry competition for high-interest savings account products at Scotiabank, involving data sourcing, cleaning, feature engineering, modeling, and automation using Python, XGBoost, and Scikit-learn."
        },
        "job_description": {
            "Role": "\u2022 Employ a full suite of technical capabilities to perform advanced statistical modeling, machine learning, and data mining techniques to identify and prevent fraudulent activities.  \u2022 Propose innovative approaches to improve fraud detection methodologies and actively contribute to the adoption of cutting-edge techniques within the team.  \u2022 Independently prepare and present high-quality deliverables, including data visualizations and model interpretations, to communicate project insights to director/executive-level audiences, influencing strategic decision-making related to fraud mitigation.  \u2022 Collaborate in the development of analytical solutions for fraud detection, providing support to team members. This includes mentoring and knowledge sharing.  \u2022 Independently prepare and present high-quality deliverables, including data visualizations and model interpretations, to communicate project insights to director/executive-level audiences, influencing strategic decision-making related to fraud mitigation.  \u2022 Continuously research and evaluate state-of-the-art analytical techniques and tools relevant to fraud detection, sharing knowledge and best practices with team members.",
            "Qualification": "\u2022 University degree in data science, statistics, computer science, operations research, or a related discipline. Preference to individuals with significant technical expertise gained through analytics self-study.  \u2022 Competence in most major areas of data science/analytics. These areas include data wrangling, data visualization, predictive modelling, statistics, machine learning, big data analytics, geospatial analytics, and optimization.  \u2022 A proven track record of developing integrated, creative analytical solutions in a business context.  \u2022 Demonstrated competence in Python, including experience with ensemble methods (e.g., XGBoost, Gradient Boosting) for classification and regression tasks, clustering algorithms (e.g., K-means, DBSCAN), and dimensionality reduction techniques (e.g., PCA, t-SNE). A strong understanding of model evaluation metrics (precision, recall, F1-score, AUC-ROC) is required. Intermediate understanding of SQL techniques and data modeling.  \u2022 Good project management, communication, and problem-solving skills.  \u2022 Experience guiding and coaching more junior staff members"
        }
    },
    {
        "job_title": "DS",
        "resume": {
            "Education": "University of Pennsylvania: Master\u2019s Degree in Computer and Information Technology (September 2021 - May 2023). McGill University: Master\u2019s Degree in Chemical Engineering (2018 - 2021). McGill University: Bachelor of Engineering in Chemical Engineering (2013 - 2018). Chengdu Meishi International School: Senior High School, Academics (2009 - 2012).",
            "Experience": "Senior Data Scientist at StackAdapt (October 2024 - Present): Based in Toronto, focusing on data-driven solutions and analytics. Data Scientist at StackAdapt (January 2023 - October 2024): Delivered data science solutions, contributing to analytics projects in Toronto. Applied Scientist at Amazon (June 2022 - September 2022): Worked in Vancouver on applied science initiatives. Data Scientist at Intact (January 2022 - April 2022): Focused on data science projects in Montreal. Research Scientist at McGill University (September 2018 - May 2021): Designed experiments to identify natural compounds for combating drug-resistant bacteria, significantly reducing drug usage and publishing a journal article. Graduate Teaching Assistant at McGill University (September 2018 - May 2020): Taught courses in Process Control, Fluid Mechanics, and Elements of Biotechnology, receiving commendations for creativity and rigor. Research Scientist at McGill University (May 2017 - December 2017): Synthesized nanocomposites for wastewater treatment, improving absorption efficiency by 42%. Research Scientist at The University of British Columbia (May 2016 - August 2016): Developed silver-coated nanoscale particles, optimizing their movement speed by 57% through chemical and data analysis. Undergraduate Research Assistant at McGill University (January 2016 - April 2016): Synthesized copolymers using advanced chemical techniques, analyzing results using GPC and NMR.",
            "Skills": "Technical skills include Python, SQL, machine learning, data visualization, regression models, clustering, deep learning (DNN, CNN, RNN, GAN), and data interpretation. Proficient in Python libraries (NumPy, Pandas, Scikit-learn, TensorFlow, PyTorch), SQL, and programming languages like Java, C++, and MATLAB. Language proficiencies include Chinese (Native or Bilingual) and English (Professional Working). Certifications in SQL, Algorithms, and Database Management.",
            "Projects": "Designed experiments to identify natural compounds for combating drug-resistant bacteria, significantly reducing drug usage and publishing a journal article. Synthesized nanocomposites for wastewater treatment, improving absorption efficiency by 42%. Developed silver-coated nanoscale particles, optimizing their movement speed by 57% through chemical and data analysis. Synthesized copolymers using advanced chemical techniques, analyzing results using GPC and NMR."
        },
        "job_description": {
            "Role": "\u2022 Innovate ML algorithms to maximize ROI and advertising performance. This ranges from creating entirely new algorithms, to improvements on state-of-the art methods, to development using a deep understanding of classic methods \u2022 Write production code, sometimes collaborating with Data Engineers, to implement the novel ML algorithms \u2022 Prototype potential algorithms and pipelines, test them using historical data, and iterate to modify based on insights",
            "Qualification": "\u2022 Have a Masters degree or PhD in Computer Science, Statistics, Operations Research, or a related field, with dual degrees a plus. \u2022 Have the ability to take an ambiguously defined task, and break it down into actionable steps \u2022 Have a comprehensive understanding of statistics, optimization and machine learning \u2022 Are proficient in coding, data structures, and algorithms \u2022 Enjoy working in a friendly, collaborative environment with others"
        }
    },
    {
        "job_title": "DS",
        "resume": {
            "Education": "University of Waterloo: Doctor of Philosophy in Statistics (2017 - 2020). The University of British Columbia: Master of Science in Statistics (2015 - 2017). University of Notre Dame: Bachelor\u2019s Degree in Applied and Computational Mathematics and Statistics (2012 - 2015).",
            "Experience": "Senior Data Scientist at Stripe (November 2023 - Present): Focuses on advanced data science applications to drive Stripe\u2019s growth and optimization efforts. Senior Data Scientist at Shopify (February 2022 - November 2023): Worked in Shopify\u2019s Growth Org, emphasizing user base expansion and monetization strategies.  Data Scientist - Enterprise Model Risk Management at RBC Capital Markets (January 2021 - February 2022): Delivered validation reports on AI and machine learning models, conducted predictive uncertainty quantification research, and developed internal Python tools for statistical model monitoring and improvement. Doctoral Researcher at University of Waterloo (January 2018 - December 2020): Proposed innovative methods for feature extraction and applied them to statistical inference and time series problems, delivering results through academic papers and conference presentations. Graduate Research Assistant at The University of British Columbia (January 2016 - August 2016): Designed Bayesian sampling algorithms and inference methods for financial market risk management and autoregressive stochastic volatility models.",
            "Skills": "Proficient in Python, R, machine learning, Bayesian statistics, predictive modeling, A/B testing, and MLOps. Language proficiencies include Chinese (Native or Bilingual) and English (Full Professional). Certifications include Deep Learning Specialization, Practical Data Science Specialization, and SAS Advanced Programmer.",
            "Projects": ""
        },
        "job_description": {
            "Role": "We\u2019re looking for a variety of Data Scientists to partner with the Product, Finance, Payments, Risk, Growth and Go-to-Market teams. You\u2019ll work closely with a specific part of the business, playing a crucial role in optimizing our systems and leveraging data to make strategic business decisions. As Data Scientists as Stripe, it\u2019s our mission to ensure that the company strategy, products, and user interactions make smart use of our rich data, using techniques like machine learning, statistical modeling, causal inference, optimization, experimentation, and all forms of analytics.",
            "Qualification": "\u2022 3-8+ years of data science/quantitative modeling experience \u2022 Proficiency in SQL and a computing language such as Python or R  \u2022 Strong knowledge and hands-on experience in several of the following areas: machine learning, statistics, optimization, product analytics, causal inference, and/or experimentation \u2022 Experience in working with cross-functional teams to deliver results \u2022 Ability to communicate results clearly and a focus on driving impact \u2022 A demonstrated ability to manage and deliver on multiple projects with a high attention to detail \u2022 Solid business acumen and experience in synthesizing complex analyses into actionable recommendations \u2022 A builder's mindset with a willingness to question assumptions and conventional wisdom \u2022 Experience deploying models in production and adjusting model thresholds to improve performance  \u2022 Experience designing, running, and analyzing complex experiments or leveraging causal inference designs \u2022 Experience with distributed tools such as Spark, Hadoop, etc. \u2022 A PhD or MS in a quantitative field (e.g., Statistics, Engineering, Mathematics, Economics, Quantitative Finance, Sciences, Operations Research)  \u2022 This role is not eligible for hire in the Greater Seattle Area or San Francisco Bay Area"
        }
    },
    {
        "job_title": "DS",
        "resume": {
            "Education": "The Hebrew University: Master of Business Administration (MBA) in Finance and Operations Research (2012 - 2015). The Hebrew University: Bachelor's Degree in Statistics and Geo-Informatics (2009 - 2012).",
            "Experience": "Senior Data Scientist at Interac Corp. (January 2022 - Present): Leading data science initiatives and developing advanced analytics solutions in Toronto. Specialist, Advanced Analytics at Interac Corp. (July 2018 - December 2021): Focused on leveraging analytics to support business objectives and strategic decision-making. Data Scientist and BI Analyst at ironSource (October 2013 - May 2018): Worked in Tel Aviv to enhance software discovery and content delivery platforms. Contributed to installation analytics and traffic monetization, serving developers, carriers, and brands.",
            "Skills": "Proficient in Python, R, and advanced statistical methods. Language proficiencies include Hebrew (Native or Bilingual), Russian (Native or Bilingual), English (Full Professional), and Arabic (Professional Working).",
            "Projects": ""
        },
        "job_description": {
            "Role": "\u2022 Collaborating with fraud product owners and software developers to enable deployment of fraud solutions that will scale across the company\u2019s ecosystem.  \u2022 Working with large complex data sets to solve difficult, non-routine analysis problems applying advanced analytical methods as needed.  \u2022 Conducting end-to-end analysis that includes data gathering and requirements specification, processing, analysis, ongoing deliverables, and presentations.  \u2022 Collaborating with business customers and fraud product owners to understand needs, recommend strategy enhancements, and deploy predictive analytics across multiple platforms.  \u2022 Researching, developing, deploying and analyzing testing strategies to continuously improve current fraud related deliverables.  \u2022 Preparing detailed documentation to transfer knowledge and satisfy governance and regulatory concerns.  \u2022 Communicating technical fraud solutions to non-technical audiences.  \u2022 Consulting on applying quantitative problem solving to business problems using analytics in both mentoring and classroom settings.",
            "Qualification": "\u2022 A degree in Business, Mathematics, Science, Statistics or equivalent combination of education and industry experience.  \u2022 3 or more years of experience in the financial industry.  \u2022 3 years or more of experience in data analytics.  \u2022 2 years or more of experience using machine learning.  \u2022 Strong knowledge and skills in mathematics.  \u2022 A strong sense of planning, priority setting, problem resolution and decision making.  \u2022 Knowledge of Interac products.  \u2022 Expert knowledge of data mining, databases, SQL and machine learning.  \u2022 Experience with the following technologies/databases: Oracle, HDFS, Redshift, Spark (PySpark), Python.  \u2022 Strong knowledge of the Canadian payment industry, payments transaction data and process flows.  \u2022 Knowledge of IT processes and infrastructure required to support analytics.  \u2022 Significant experience working with implementing concepts, such as predictive modeling, profiling, feature development, behavioral analysis, clustering, and data mining.  \u2022 Excellent inter-personal skills, communication, problem solving, conflict management, client-focused, customer-driven and able to work under pressure.  \u2022 Familiarity with Cloudera, Jupyter, Github, AWS is an asset."
        }
    },
    {
        "job_title": "DS",
        "resume": {
            "Education": "University of Toronto: Master of Science in Statistics (2021 - 2022). University of Toronto: Bachelor of Science in Applied Statistics (2017 - 2021).",
            "Experience": "Data Scientist at Genesys (March 2023 - Present): Develops predictive models, conducts statistical analysis, and delivers insights to support decision-making. Data Analyst Intern at Alibaba Group (May 2021 - August 2021): Provided analytics support for RT-Mart, focusing on data-driven business decisions. Research Assistant at University of Toronto (November 2020 - April 2021): Conducted a research project analyzing library online resource usage by integrating large datasets and building generalized regression models. Teaching Assistant at University of Toronto (September 2020 - April 2021): Led tutorials for STA130 (Introduction to Statistical Reasoning and Data Science) and graded assignments.",
            "Skills": "Proficient in Python, R, SQL, and data visualization tools like Tableau, PowerBI, and R-Shiny. Experienced in machine learning techniques such as CART, boosting, bagging, and clustering, as well as statistical methods like causal inference, experimental design, regression analysis, and Bayesian inference.",
            "Projects": ""
        },
        "job_description": {
            "Role": "Roles, (including but not limited to):  Business Analytics:   \u2022 Gain a quick understanding of complex business problems and the outcomes required of a data solution. \u2022 Deliver prototypes and models for use in production experiments. \u2022 Work with unstructured data to develop feature data that can be used in models. \u2022 Partner with data experts to acquire, cleanse, and structure data for purpose. \u2022 Develop stories that explain the complexity of models and their output that can reach a variety of audiences (executives, leaders, individual contributors) with specific recommendations on how to use the output to drive better decisions. \u2022 Develop appropriate data models to drive business decisions. \u2022 Design and implement appropriate data-gathering methodology for business needs. \u2022 Create experimental frameworks for data collection and evaluation. \u2022 Partner with other analytics teams to leverage the tools, patterns, and analytics platforms to provide access to the model data (inputs and outputs) across Genesys organizations via reports, microservices, and data products.   Sales Operations Excellence:   \u2022 Work with Sr. Director, to drive Globally Consistent Cadence schedule; including but not limited to: \u2022 Create reports and presentations for colleagues. \u2022 Deliver analysis of data, including scoring and collection modeling. \u2022 Design and deliver analysis across data sets to support business KPIs.  Measures for Success:   \u2022 Curation and development of data sources, reporting templates, and predictive analytics for management. \u2022 Identify, analyze, and interpret trends in complex data sets. \u2022 Coach, enable, and work with stakeholders to ensure they can derive insights and drive action from produced analytics \u2022 Able to operate successfully in a lean, fast-paced organisation, and to create a vision and organisation that can scale quickly",
            "Qualification": "\u2022 Bachelor\u2019s degree Business, Economics, Computer Science, Information Management or Statistics, or 5 years of relevant work-related experience in a quantitative field \u2022 5+ years of experience in advanced analytics/ predictive modeling \u2022 5+ years of experience in the full lifecycle of analytics using Enterprise Tools: Tableau, QlikView, PowerBI \u2022 5+ years of SQL skills in ANSI SQL / T-SQL with excellent hands-on exposure to database structures & principles \u2022 Python, Scala, Java, R experience in big data settings \u2022 Experience with one or more machine learning frameworks such as TensorFlow, Torch, PyTorch, Spark ML \u2022 Expertise in one or more areas of specialization such as social psychology, consumer behavior predictions, NLP, statistics, econometrics and their associated products and algorithms \u2022 Experience with deployment of models in cloud environments such as AWS Sagemaker"
        }
    },
    {
        "job_title": "DS",
        "resume": {
            "Education": "Bachelor of Mathematics, Double Major in Actuarial Science and Statistics (2017 - 2022).",
            "Experience": "Data Scientist at a ride-sharing company (June 2024 - Present): Working in Toronto, focusing on data science initiatives to enhance decision-making. Data Scientist at an insurance company (July 2022 - June 2024): Built and deployed an XGBoost regression model to optimize insurance product pricing, contributing to a 12% annual revenue increase. Created automated visualization tools using Python and shell scripting, reducing manual labor by over 25 hours monthly. Mentored data scientist interns and developed documentation for processes. Actuarial Analyst at the same insurance company (September 2021 - December 2021): Implemented a gradient-boosting model for fraud detection, resulting in a 14% increase in detection rates. Developed a K-means clustering algorithm for customer segmentation, contributing to a $125,000 annual revenue boost. Conducted statistical analysis on customer retention data using SAS and presented insights to stakeholders. Data Scientist at another insurance company (May 2021 - August 2021): Built and deployed ETL data pipelines to process semi-structured data from multiple sources into a centralized database using SQL and Python. Automated monthly reporting processes, saving over 60 hours of manual work each month. Previous roles include actuarial analyst positions at various financial and insurance companies and an account plan reporting analyst role at a university.",
            "Skills": "Technical Skills: Python, SQL (Snowflake), ETL processes, Airflow, Shell scripting. Machine Learning: XGBoost, Gradient Boosting, K-means Clustering. Data Visualization: Experience creating impactful visualizations to deliver actionable insights. Other: Mentoring, Process Documentation, Statistical Analysis using SAS.",
            "Projects": "Built and deployed an XGBoost regression model to optimize insurance product pricing, contributing to a 12% annual revenue increase. Implemented a gradient-boosting model for fraud detection, resulting in a 14% increase in detection rates. Developed a K-means clustering algorithm for customer segmentation, contributing to a $125,000 annual revenue boost. Built and deployed ETL data pipelines to process semi-structured data from multiple sources into a centralized database."
        },
        "job_description": {
            "Role": "You will invent new experiences and influence customer-facing shopping experiences to help suppliers grow their retail business and the auction dynamics that leverage native advertising; this is your opportunity to work within the fastest-growing businesses across all of Amazon! Define a long-term science vision for our advertising business, driven fundamentally from our customers' needs, translating that direction into specific plans for research and applied scientists, as well as engineering and product teams. This role combines science leadership, organizational ability, technical strength, product focus, and business understanding.",
            "Qualification": "3+ years of building models for business application experience \u2022  PhD, or Master's degree and 4+ years of CS, CE, ML or related field experience \u2022  Experience programming in Java, C++, Python or related language \u2022  Experience in any of the following areas: algorithms and data structures, parsing, numerical optimization, data mining, parallel and distributed computing, high-performance computing \u2022  Experience in solving business problems through machine learning, data mining and statistical algorithms \u2022  Experience in designing experiments and statistical analysis of results   Preferred Qualifications   \u2022  Experience using Unix/Linux \u2022  Experience in professional software development"
        }
    },
    {
        "job_title": "DS",
        "resume": {
            "Education": "University of Waterloo: Bachelor of Mathematics, Double Major in Actuarial Science & Statistics (2017 - 2022).",
            "Experience": "Data Scientist at Lyft (June 2024 - Present): Works in Toronto, driving data science initiatives for enhanced decision-making. Data Scientist at Intact (July 2022 - June 2024): Built and deployed an XGBoost Regression model optimizing insurance product pricing, contributing to a 12% annual revenue increase. Created automated visualization tools and mentored interns, improving operational efficiency and documentation. Actuarial Analyst at Intact (September 2021 - December 2021): Developed gradient-boosting models for fraud detection and implemented customer segmentation with K-means clustering, enhancing detection rates and revenue. Conducted statistical analyses on customer retention data. Data Scientist at Economical Insurance (May 2021 - August 2021): Built and deployed ETL data pipelines, ensuring integration with existing data frameworks, and automated reporting processes to save significant manual effort. Actuarial Analyst at Intact (September 2020 - December 2020): Conducted actuarial analyses to support business strategies. Actuarial Associate at PwC (January 2020 - April 2020): Contributed to actuarial consulting projects. Actuarial Analyst at Desjardins General Insurance Group (May 2019 - August 2019): Supported insurance product analytics. Account Plan Reporting Analyst at University of Waterloo (May 2018 - August 2018): Provided reporting support for account planning activities. Financial Advisory Intern at Deloitte Mauritius (March 2017 - April 2017): Assisted in financial advisory tasks.",
            "Skills": "Proficient in Python, SQL (Snowflake), ETL processes, and data visualization. Experienced in machine learning techniques, including XGBoost, gradient boosting, and clustering algorithms.",
            "Projects": ""
        },
        "job_description": {
            "Role": "\u2022 Leverage data and analytic frameworks to identify opportunities for growth and efficiency  \u2022 Partner with product managers, engineers, marketers, designers, and operators to translate data insights into decisions and action \u2022 Design and analyze online experiments; communicate results and act on launch decisions \u2022 Develop analytical frameworks to monitor business and product performance \u2022 Establish metrics that measure the health of our products, as well as rider and driver experience \u2022 Provide coaching and technical guidance for the team \u2022 Prioritize and lead deep dives into our data to uncover new product and business opportunities \u2022 Facilitate and foster data-driven and informed decision making and prioritization",
            "Qualification": "\u2022 Ph.D. in Statistics, Operations Research, Mathematics, Computer Science, or other quantitative fields or related work experience.  \u2022 Passion for solving unstructured and non-standard, ambiguous mathematical problems by leveraging expertise in one or multiple fields. \u2022 Strong skills in optimization, statistics, and causal inference.  \u2022 End-to-end experience with data, including querying, aggregation, analysis, and visualization. \u2022 Proficiency with Python, or another interpreted programming language like R or Matlab \u2022 Strong communicator. Able to coordinate with several teams of data scientists to deliver on complex initiatives.  \u2022 Strong business sense and understanding of experimentation methodologies. \u2022 Proficiency in SQL - able to write structured and efficient queries on large data sets. \u2022 Experience in online experimentation and statistical analysis. \u2022 Strong oral and written communication skills, and ability to collaborate with and influence cross-functional partners."
        }
    },
    {
        "job_title": "DS",
        "resume": {
            "Education": "University of Alberta: Master of Science in Electrical Engineering (September 2022 - September 2024). University of Calgary: Bachelor\u2019s Degree in Mathematics (Honors) (2017 - 2022).",
            "Experience": "Data Science Intern at Faire (October 2024 - Present): Contributes to data science initiatives in Canada.",
            "Skills": "Proficient in Python, SQL, MATLAB, Spring Boot, and C#. Language proficiencies include Mandarin Chinese (Native or Bilingual) and English (Professional Working). Certifications include Python for Everybody Specialization and IBM Data Science Specialization.",
            "Projects": "Spring Boot Project of Student Management System (December 2020 - January 2021): Developed a Spring Boot project utilizing Spring Security, JPA, and Thymeleaf templates. Implemented role-specific functionalities for admin, student, and instructor logins. API for a Simple Railway System (March 2020 - May 2020): Final project for the course CPSC 471 (Database Management System). Created an API in C# connected to a MySQL database, capable of retrieving and updating information through API requests."
        },
        "job_description": {
            "Role": "Faire is using machine learning to change wholesale and help local retailers compete with Amazon and big box stores. Our experienced data scientists and machine learning engineers are developing solutions related to discovery, ranking, search, recommendations, ads, logistics, underwriting, and more - all with the goal of helping local retail thrive.  As a member of the Discovery Data team you\u2019ll be responsible for one of the following areas:   \u2022 Search: Optimizing search through query understanding, retrieval, ranking, post-ranking and whole-page optimization with state-of-art technologies including embeddings, graph learning, deep learning and large language models (LLMs). \u2022 Personalization: Personalizing recommendation surfaces through embeddings, near-real-time / streaming signals, explore-exploit, and diversification. \u2022 Ads / Sponsored Products: Joining a newly established team building Ads Delivery and Advertiser Optimization from the ground up and tackling challenges in ads targeting, retrieval, prediction/ranking, bidding, pacing, and auction design.    Our team already includes experienced Data Scientists and Machine Learning Engineers from Uber, Airbnb, Square, Facebook, LinkedIn and Pinterest. We're a lean, talented team with high opportunity for direct product impact and ownership.",
            "Qualification": "\u2022 Experience with leading cross-team and cross-functional technical strategy and roadmap, solving long-term open-ended problems, and consistently driving significant business impact for the whole org. \u2022 5+ years of industry experience using machine learning to solve real-world problems \u2022 Experience and strong understanding of search / personalization / ads for product development  \u2022 Strong programming skills  \u2022 An excitement and willingness to learn new tools and techniques  \u2022 Experience with deep learning  \u2022 The ability to contribute to team strategy and to lead model development without supervision  \u2022 Strong communication skills and the ability to work with others in a closely collaborative team environment"
        }
    },
    {
        "job_title": "DS",
        "resume": {
            "Education": "Langara College: Postgraduate Degree in Data Analytics (2020 - 2021). Panjab University: Bachelor of Engineering in Computer Science (2005 - 2009).",
            "Experience": "Senior Data Analyst at McAfee (May 2021 - Present): Designed and executed complex SQL queries for large datasets, maintained ETL data pipelines in Databricks, and developed Tableau dashboards for performance analysis. Presented business insights to senior leadership and provided training to stakeholders. Managed a team of analysts and engineers, mentoring them while driving analysis initiatives. Analytics Engineer at HSBC Global Banking and Markets (January 2016 - December 2019): Assisted in data warehouse design, created Tableau dashboards for financial KPIs, and implemented machine learning models for classification and prediction. Enhanced data processing efficiency using Python and SQL. IT Analyst at Tata Consultancy Services (September 2015 - January 2016): Developed database architecture and optimized performance for custody data warehouse projects. Created Tableau reports for analyzing financial KPIs. Associate Consultant at Virtusa (March 2014 - August 2015): Developed and optimized database queries, enhanced ETL job performance, and led a team for a custody data warehouse project. Senior System Engineer at Infosys (August 2009 - March 2014): Customized banking software, automated bulk data operations, and prepared requirement documents and designs for retail banking modules.",
            "Skills": "Proficient in Python, SQL, Tableau, and PL/SQL. Experienced in ETL processes, machine learning (classification, regression, NLP), data visualization, and database optimization. Familiar with tools like Databricks, Airflow, and statistical analysis methods.",
            "Projects": "Capstone Project at The University of British Columbia (February 2021 - April 2021): Applied NLP techniques, including LSTM and Glove vectorization, for text classification using Python libraries."
        },
        "job_description": {
            "Role": "\u2022 Ability to attend meetings and discussions during overlapping Pacific Standard Time (PST) hours (must-have). \u2022 Conceptualize, design, and implement state-of-the-art ML models for dynamic pricing strategies and personalized product recommendations. \u2022 Develop, implement, and deploy machine learning models that leverage our unique combination of user behavior and subscription data to improve consumer value from our products. \u2022 Engineer and maintain large-scale consumer behavioral feature stores while ensuring scalability and performance. \u2022 Develop and maintain data pipelines and infrastructure to support efficient and scalable ML model development and deployment. \u2022 Collaborate with cross-functional teams (Marketing, Product, Sales) to ensure your solutions align with strategic objectives and deliver real-world impact. \u2022 Create algorithms for optimizing consumer journeys and increasing conversion and monetization. \u2022 Design, analyze, and troubleshoot controlled experiments (Causal A/B tests, Multivariate tests) to validate your solutions and measure their effectiveness.",
            "Qualification": "\u2022 7 to 9 years of experience in one or more of the following areas: machine learning (including deep learning), recommendation systems, pattern recognition, data mining or artificial intelligence. \u2022 Proficient in Python, SQL, intermediate data engineering skill set with tools, libraries, or frameworks such as MapReduce, Hadoop, Hive and Big Data technologies, scikit-learn, Keras, TensorFlow, PyTorch etc. \u2022 Experience with various ML techniques and frameworks, e.g., data discretization, normalization, sampling, linear regression, decision trees, deep neural networks, etc. \u2022 Experience in building industry-standard recommender systems and pricing models. \u2022 Expertise in MLOps, ML Engineering and Solution Design."
        }
    },
    {
        "job_title": "DS",
        "resume": {
            "Education": "University of Waterloo Master of Mathematics (Thesis), Computer Science - Natural Language Processing (2019\u20132020) Queen's University Bachelor of Science - BS, Computer Science (2016\u20132018)",
            "Experience": "Polar Asset Management Partners Inc. Quant/Data Scientist (October 2022 \u2013 Present, Toronto, Ontario, Canada) RBC Capital Markets Research Data Scientist (May 2021 \u2013 September 2022, 1 year 5 months) Led equity research reports by modeling alternative data (texts, geo-locations, etc.). Developed ESG back-testing tools for S&P 500, fostering cross-functional collaborations. Integrated SOTA NLP algorithms to outperform benchmarks in predictions. AGF Investments Quant Research Analyst (October 2020 \u2013 May 2021, 8 months, Toronto, Ontario, Canada) Created AGFIQ sentiment dictionary and implemented transformer models for financial data. Worked on ESG topic modeling and back-testing multiple factors for investment universes. Research Intern in NLP (September 2019 \u2013 October 2020, 1 year 2 months, Toronto, Ontario, Canada) University of Waterloo Research Assistant & Teaching Assistant (January 2019 \u2013 October 2020, 1 year 10 months) Conducted research on deep attention-based multiple-instance learning for interpretable sentiment analysis. Taught Introduction to Machine Learning.",
            "Skills": "Machine Learning Natural Language Processing (NLP) Python, PyTorch, Spark, MLFlow, Flask, SQL",
            "Projects": "Developed predictive ESG score back-testing tools, improving collaborations and client engagement. Built financial NLP applications, including transformer models for analyzing financial time-series data. Researched interpretable AI for responsible investment decisions and sentiment analysis."
        },
        "job_description": {
            "Role": "Build, maintain, deploy, and improve our data science models and products \u2013 You will work with a team of experienced Developers and Data Scientists on custom analytics products using market data and alternative data. The custom models and solutions you build will be used by internal teams across the firm: Portfolio Management, Trading, Risk, Compliance, Business Development, Operations, and Quant Research. You will focus on developing data products \u2013 You\u2019ll focus on building, documenting, and deploying data transformation, data visualization, model training, and inference pipelines. You will have the opportunity to work with Portfolio Managers and Investment Teams to actively enhance Trading & Analytics software. You will manage individual projects, priorities, and results. Collaborate with your peers \u2013 You will provide and receive direct and regular feedback from your team and internal customers. You will receive coaching, mentorship, and development opportunities from Senior Technologists, Portfolio Managers, and others in the organization.",
            "Qualification": "You have a passion for data science, finance, and problem solving \u2013 You have hands-on experience with Python, SQL, and common data tools. You have a good understanding of data quality issues and are diligent to ensure high quality inputs are fed into models. You are eager to continuously expand your knowledge about technology and finance. You have already built and deployed statistical machine learning models in production and may have explored emerging artificial intelligence tools such as language models. You are driven to be a top developer \u2013 You are the go-to data scientist in your area or team (or even your organization). You are highly recognized for your excellent productivity, creativity, technical capability, sense of ownership, and collaborative attitude. You have a keen interest in the financial industry \u2013 You are eager to learn about the financial industry from your work, peers, and industry experts. Previous experience with custom investment research and building analytical models in a major asset class (equities, rates, credit, or commodities) is highly desirable. You can balance writing clean and quality code with prompt execution and delivery \u2013 You have a strong work ethic and are able to balance working in a fast-paced environment with writing quality code. You are an excellent communicator \u2013 You can communicate with people of varying levels of technical expertise to dissect, test, and execute projects. You enjoy troubleshooting and working on solving interesting and complicated problems."
        }
    }
]